# 共识



每个矿工 都 随机赋予一个  Distance Space 不提供服务的probability

| 矿工 | Distance | Storage Space | Probability |
| ---- | -------- | ------------- | ----------- |

矿工 即 Storage Node，每一个node要 存储Batch，对于Batch如何存储，遍历每一个构建的Batch，按照上述三种方法分别计算每种方法如何选择Node，**如何选择存储的规则如下**： 

| 方法   |                                                              |      |      |
| ------ | ------------------------------------------------------------ | ---- | ---- |
| 方法一 | 信誉和距离都考虑，根据 （ 距离 + 存储空间 ）计算Score，并根据Score rank，其余节点要求rank排名最高者提供PoA,成功提供PoA者获得记账权，能否提供PoA的概率即Probability。 |      |      |
| 方法二 | 只考虑信誉，根据Storage Space + Probability 计算出Score rank，随机取一个信誉排名高者 |      |      |
| 方法三 | 只考虑距离，根据Storage Space + Distance 计算出Score rank，随机取一个距离排名高者 |      |      |

如何**比较三种共识算法**：

两个指标： 无服务次数、有服务时延

|              | 无服务次数（概率：无服务次数/总请求次数） | 有服务时的 时延 |
| ------------ | ----------------------------------------- | --------------- |
| 有信誉无距离 |                                           |                 |
| 无信誉有距离 |                                           |                 |
| 有信誉有距离 |                                           |                 |

两个指标的计算是在  Batch已经按照相应的算法存储在各个node中的基础之上， 而后 用户的query需要访问Batch时会访问到node，此时再根据 **Probability** 决定node是否提供了服务，如果无服务，记录次数，如果有服务，计算相应的时延。



### 按Device构图

- 数据集整合层面
  - 三个数据集分开处理
  - 对于单个数据集：
    - 上链时间：10 s
    - 最小单元包含数据点：10 个
    - 每个Batch包含的数据点个数：10 个
    - 不妨设定 “上链时间 == 最小单元包含数据点个数”，则有“最小单元包含数据点 == 设备数”
    - 每隔固定的上链时间之后， 比如20个设备10s内产生了 200个数据，按照最小单元打包成10个数据一个点，共有20个点，每个点中的数据由网关接收到数据的顺序决定，故每个点中可能包含来自各个设备的数据，20个点再进行Batch，比如10个点打包为一个Batch，那就打包成2个Batch，这2个Batch中的数据非常杂乱（这就天然地导致 query 一段时间内一部分设备产生的数据时需要获取非常多的Batch）
    - 如果对于这200个数据先按照设备进行打包成最小单元，各个设备10s内产生的数据会处于同一个最小单元中，之后再按照“设备图”的子图划分结果进行Batch，比如20个设备要求划分成几个Class(即Class_number = Batch_number = 数据点个数 / 每个Batch包含的数据点个数 = 设备数 / 每个Batch包含的数据点个数)，划分成功之后按照相关的Batch存储。这种方式首先保证了数据点中的数据有序，再通过子图划分的方式保证了 设备编号相近的 Device 和 经常被同时访问的Device 会被分到同样的Batch中。
- Device图的权重
  - Initialization：仅根据Device id来进行相应的初始化
  - 根据 Trace 迭代：每10s的数据会有一批相应的查询生成，0-10s的Batch根据init_graph来进行子图划分，并生成相应的 Trace，根据这部分 Trace 会对graph做迭代，迭代完成后，10-20s的数据根据0-10s的 Trace 迭代后得到的图进行子图划分构建Batch。迭代公式：（与此前一致）
  - 生成 Trace，要求每个上链时间间隔内的数据上 产生的 Query 都服从于同样的数据分布（即同时被访问到的设备都比较容易被访问）
